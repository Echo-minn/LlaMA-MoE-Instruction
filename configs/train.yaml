seed: 42
output_dir: outputs/checkpoints/llama-agentos-qlora
logging_dir: outputs/logs
train:
  num_train_epochs: 3
  per_device_train_batch_size: 2
  gradient_accumulation_steps: 8
  learning_rate: 2.0e-4
  weight_decay: 0.0
  max_grad_norm: 1.0
  warmup_ratio: 0.03
  lr_scheduler_type: cosine
  logging_steps: 10
  save_steps: 200
  eval_steps: 200
  save_total_limit: 3
  bf16: true
  fp16: false
  dataloader_num_workers: 2
  report_to: null  # set 'wandb' to enable
eval:
  per_device_eval_batch_size: 2
  max_eval_samples: 1024
  compute_ppl: true

